# Main .py file which will be used for the model
model-type: showattend

# Target word embedding vector dimension
trg-emb-dim: 620

# Source image related parameters
conv-dim: 512

# Decoder RNN's hidden layer dimension
rnn-dim: 1000
dec-type: gru_cond

# Maximum target sequence length
maxlen: 50

# adadelta, adam, sgd or rmsprop
optimizer: adadelta

# Learning rate (only for SGD)
lrate: 0.0001

# 0: no, otherwise dropout probability
dropout: 0.0

# 0: no, otherwise weight decay factor
decay-c: 0.0005

# -1: no, otherwise maximum gradient norm
clip-c: -1.0

# 0: no, otherwise alpha regularization factor
alpha-c: 0.0

# batch size
batch-size: 32

# how much validation period will we wait to do early stopping
patience: 20

# Maximum number of epochs before stopping training
max-epochs: 100

# validation frequency in terms of minibatch updates
# 0 means at end of epochs
valid-freq: 0

# Sort batches wrt target sequence lengths
sort: True

# Use BLEU as validation metric
use-bleu: True

# 0: use all vocabulary, otherwise upper limit as integer
n-words-trg: 0

# Where to save model params, weights and training log file
model-path:     ~/wmt16/models

# Source is a matrix of 28500 x 14*14*512
data: { \
  "train_idx":               '~/wmt16/data/text/lium.moses.lc.tok/lium_train.id', \
  "train_src": ['img_feats', '~/wmt16/data/images/npy/conv54_vgg_feats_hdf5-flickr30k.train.npy'], \
  "train_trg": ['text'     , '~/wmt16/data/text/lium.moses.lc.tok/lium_train.tok.de'], \
  "valid_src": ['img_feats', '~/wmt16/data/images/npy/conv54_vgg_feats_hdf5-flickr30k.valid.npy'], \
  "valid_trg": ['text'     , '~/wmt16/data/text/lium.moses.lc.tok/val.tok.de'], \
  }

# Dictionaries if necessary
dicts: { \
  "trg":  "~/wmt16/data/text/lium.moses.lc.tok/lium_train.tok.de.pkl" \
  }

# auto: select the first available, otherwise integer
device-id: auto

# reload existing model and continue training
restore: False

# profile theano ops
profile: False
