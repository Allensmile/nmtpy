# Main .py file which will be used for the model
model_type: rnnlm

# Embedding vector dimension
in_emb_dim: 620
out_emb_dim: 620

# RNN's hidden layer dimension
rnn_dim: 1000
enc_type: ff
rnn_type: gru

# adadelta, adam, sgd or rmsprop
optimizer: adadelta

# Learning rate (only for SGD)
lrate: 0.0001

# 0: no, otherwise dropout probability
dropout: 0.0

# 0: no, otherwise weight decay factor
decay_c: 0.0005

# -1: no, otherwise maximum gradient norm
clip_c: -1.0

# 0: no, otherwise alpha regularization factor
alpha_c: 0.0

# batch size
batch_size: 32

# how much validation period will we wait
# to do early stopping
patience: 10

# Maximum number of epochs before stopping training
max_epochs: 100

# validation frequency in terms of minibatch updates
valid_freq: 1000

# Use BLEU as additional validation metric
valid_metric: px

# 0: use all vocabulary, otherwise upper limit as integer
n_words: 0

# Where to save model params, weights and training log file
model_path:     /lium/trad4a/wmt/2016/barrault/rnnlm/models

# Dictionaries if necessary
dicts: { \
  "src":  "/lium/trad4a/wmt/2016/caglayan/data/text/task1.lium.moses.lc.tok/lium_train.tok.en.pkl"\
  }

data: { \
  "train_src": '/lium/trad4a/wmt/2016/caglayan/data/text/task1.lium.moses.lc.tok/lium_train.tok.en', \
  "valid_src": '/lium/trad4a/wmt/2016/caglayan/data/text/task1.lium.moses.lc.tok/val.tok.en', \
  }
