# Main .py file which will be used for the model
model-type: fusion_concat_ind_ind
norm-cost: False
layer-norm: False
data-mode: all
shuffle-mode: simple

# Embedding vector dimension
embedding-dim: 620

# RNN's hidden layer dimension
rnn-dim: 1000

# ResNet feature dimension
conv-dim: 1024

# adadelta, adam, sgd or rmsprop
optimizer: adam

# Learning rate (only for SGD)
lrate: 0.0002

# 0: no, otherwise weight decay factor
decay-c: 1e-5

# -1: no, otherwise maximum gradient norm
clip-c: 5

# 0: no, otherwise alpha regularization factor
alpha-c: 0.

# batch size
batch-size: 32

# how much validation period will we wait
# to do early stopping
patience: 30

# Maximum number of epochs before stopping training
max-epochs: 200

# validation frequency in terms of minibatch updates
valid-freq: 1000
valid-metric: bleu

# Set filter to compound for correct metric computation
filter: bpe
weight-init: xavier

# 0: use all vocabulary, otherwise upper limit as integer
n-words-src: 0
n-words-trg: 0

# Where to save model params, weights and training log file
model-path:     ~/wmt16-task1

# Dictionaries if necessary
dicts: { \
  "src":  "~/wmt16/data/task1/processed/bpe20000/train.norm.max50.tok.lc.bpe.en.pkl", \
  "trg":  "~/wmt16/data/task1/processed/bpe20000/train.norm.max50.tok.lc.bpe.de.pkl", \
  }

data: { \
  "train_img" : '/lium/trad4a/wmt/2016/data/resnet-feats/flickr30k_ResNets50_blck4_train.npy', \
  "valid_img" : '/lium/trad4a/wmt/2016/data/resnet-feats/flickr30k_ResNets50_blck4_val.npy', \
  "train_src" : '~/wmt16/data/task1/processed/bpe20000/train.pkl', \
  "valid_src" : '~/wmt16/data/task1/processed/bpe20000/valid.pkl', \
  # This is the same file with BPE reverted to be used by nmt-translate for metric computation
  "valid_trg": '~/wmt16/data/task1/raw.norm/valid.norm.max50.tok.lc.de', \
  }
