# Main .py file which will be used for the model
model-type: attention

# Embedding vector dimension
embedding-dim: 16

# RNN's hidden layer dimension
rnn-dim: 32

# Maximum sequence length
maxlen: 50

# adadelta, adam, sgd or rmsprop
optimizer: adadelta

# Learning rate (only for SGD)
lrate: 0.0001

# 0: no, otherwise dropout probability
dropout: 0.0

# 0: no, otherwise weight decay factor
decay-c: 0.

# -1: no, otherwise maximum gradient norm
clip-c: -1.0

# 0: no, otherwise alpha regularization factor
alpha-c: 0.0

# batch size
batch-size: 25

# how much validation period will we wait
# to do early stopping
patience: 100

# Maximum number of epochs before stopping training
max-epochs: 20

# validation frequency in terms of minibatch updates
valid-freq: 100000

# Use CER as additional validation metric
valid-metric: px

# 0: use all vocabulary, otherwise upper limit as integer
n-words-src: 0
n-words-trg: 0

# Where to save model params, weights and training log file
model-path:     ~/nmtpy-models

# Dictionaries if necessary
dicts: { \
  "src":     "~/data/nathalie-edwin/ed/all10pc/all.train+dev+test.mot.pkl", \
  "trg":     "~/data/nathalie-edwin/ed/all10pc/all.train+dev+test.tag.pkl", \
  }

data: { \
  "train_src": '~/data/nathalie-edwin/ed/train10pc/train.mot', \
  "train_trg": '~/data/nathalie-edwin/ed/train10pc/train.tag', \
  "valid_src": '~/data/nathalie-edwin/ed/dev10pc/dev.mot', \
  "valid_trg": '~/data/nathalie-edwin/ref/concept10pc/utf8/media_dev.concept.ref', \
   }
