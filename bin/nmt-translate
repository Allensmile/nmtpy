#!/usr/bin/env python

"""Translates a source file using a translation model."""

import os
import sys
import glob
import atexit
import cPickle
import argparse
import importlib
from multiprocessing import Process, Queue, cpu_count

import numpy as np

from nmtpy.logger import Logger
from nmtpy.config import Config
from nmtpy.search import gen_sample, forced_decoding
from nmtpy.metrics import get_scorer
from nmtpy.nmtutils import idx_to_sent
from nmtpy.sysutils import *
from nmtpy.iterators import get_iterator
import nmtpy.cleanup as cleanup

log = Logger._logger

"""Worker process which does beam search."""
def translate_model(queue, rqueue, pid, model, beam_size, unnormalized, nbest, argmax=False, force_dec=False, seed=1234):
    from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams
    trng = RandomStreams(seed)
    model.build_sampler()

    while True:
        req = queue.get()

        # We should avoid this
        if req is None:
            break

        idx, data_dict = req[0], req[1]
        sidx = 0

        if force_dec:
            target = data_dict['y_forced']
            del data_dict['y_forced']
            f_init, f_next = model.f_init, model.f_next
            sample, score = forced_decoding(f_init, f_next, data_dict.values(), target)
            sample = [sample]
            score = np.array(score)

        elif argmax:
            # Get the 1best for each distribution
            # FIXME: Should pass trng?
            f_init, f_next = model.f_init, model.f_next
            sample, score = gen_sample(f_init, f_next, data_dict.values(), maxlen=50, argmax=True)
            sample = [sample]
            score = np.array(score)
        else:
            # Use model specific beam search
            sample, score = model.beam_search(data_dict.values(), beam_size=beam_size, maxlen=50)

        # normalize scores according to sequence lengths
        if not unnormalized:
            lengths = np.array([len(s) for s in sample])
            score = score / lengths

        if nbest > 1:
            sidx = np.argsort(score)[:nbest]
        else:
            sidx = np.argmin(score)

        rqueue.put((idx, np.array(sample)[sidx], score[sidx]))

"""Translator starts worker processes, delegates source iterator
to them, waits for the results."""
class Translator(object):
    def __init__(self, beam_size, src_file=None, ref_files=None, nbest=1, n_jobs=10,
                       unnorm=False, seed=1234, force_dec=False, argmax=False):

        self.beam_size = beam_size

        self.src_file = src_file
        self.ref_files = None

        if ref_files:
            # Add ability to use wildcards
            self.ref_files = glob.glob(ref_files)

        self.nbest = nbest
        self.n_jobs = n_jobs
        self.unnorm = unnorm
        self.argmax = argmax
        self.force_dec = force_dec
        self.seed = seed

        # Create worker process pool
        self.processes = [None] * self.n_jobs

    def set_model_params(self):
        # load model parameters and set theano shared variables
        self.tparams = self.__obj.load_params(np.load(self.model_file))
        self.__obj.set_dropout(False)

    def set_model_options(self, model_options, model_file):
        # pkl file
        self.model_options = model_options
        # npz file
        self.model_file = model_file

        # Import the module
        self.__class = importlib.import_module("nmtpy.models.%s" % self.model_options['model_type']).Model

        # Remove trng for compatibility with earlier models
        if 'trng' in self.model_options:
            del self.model_options['trng']

        # Create the model
        self.__obj = self.__class(seed=self.seed, **self.model_options)

        # invert dictionary
        self.ref_idict = dict([[v,k] for k,v in self.__obj.trg_dict.iteritems()])

        # If not available, translate on validation set
        if not self.src_file and not self.ref_files:
            log.info("No test sentences file given, assuming validation dataset.")

            self.src_file  = self.__obj.data['valid_src']
            # FIXME: Backward compatibility with old type of config
            if isinstance(self.src_file, list):
                self.src_file = self.src_file[-1]

            self.ref_files = self.__obj.data['valid_trg']

            # Allow multiple reference files
            if isinstance(self.ref_files, str):
                self.ref_files = list([self.ref_files])
            elif isinstance(self.ref_files, list):
                # FIXME: Backward compatibility with old type of config
                if not self.ref_files[0].startswith("/"):
                    self.ref_files.pop(0)


        log.info("Source file")
        log.info("  %s" % self.src_file)
        log.info("Reference file(s)")
        for f in self.ref_files:
            log.info("  %s" % f)

        src_iter_type = self.__obj.valid_src_iter
        trg_iter_type = self.__obj.valid_trg_iter

        if src_iter_type == 'img_feats':
            self.iterator = get_iterator('img_feats')(self.src_file, batch_size=1,
                                                      do_mask=False, n_timesteps=self.__obj.n_timesteps)
        elif src_iter_type in ('text', 'bitext'):
            # No need to use the bitext iterator in translation, override it with text.
            self.iterator = get_iterator('text')(self.src_file, self.__obj.src_dict,
                                                 batch_size=1, n_words=self.__obj.n_words_src)
        self.iterator.prepare_batches()

        if self.force_dec:
            # We need to have an iterator for the references as well
            assert len(self.ref_files) == 1
            self.ref_iterator = get_iterator('text')(self.ref_files[0], self.__obj.trg_dict, batch_size=1,
                                                     n_words=self.__obj.n_words_trg,
                                                     data_name='y_forced', do_mask=False)
            self.ref_iterator.prepare_batches()

    def start(self):
        # create input and output queues for processes
        write_queue = Queue()
        read_queue = Queue()
        # Create processes
        for idx in xrange(self.n_jobs):
            self.processes[idx] = \
                    Process(target=translate_model,
                            args=(write_queue, read_queue, idx, self.__obj, self.beam_size, self.unnorm,
                                  self.nbest, self.argmax, self.force_dec, self.seed))
            self.processes[idx].start()
            cleanup.register_proc(self.processes[idx].pid)

        cleanup.register_handler()

        # Send data to worker processes
        for idx, data in enumerate(self.iterator):
            # Is it forced decoding?
            if self.force_dec and self.ref_iterator:
                data['y_forced'] = (next(self.ref_iterator)[1])['y_forced'].flatten()
            write_queue.put((idx, data))

        self.n_sentences = idx + 1
        log.info("Distributed %d sentences to worker processes." % self.n_sentences)

        # Receive the results
        self.trans  = [None] * self.n_sentences
        self.scores = [None] * self.n_sentences

        t = time.time()
        for i in xrange(self.n_sentences):
            resp = read_queue.get()
            self.trans[resp[0]] = resp[1]
            self.scores[resp[0]] = resp[2]
            if (i+1) % 100 == 0:
                t = time.time() - t
                log.info("%d/%d sentences completed (%.2f seconds)" % ((i+1), self.n_sentences, t))
                t = time.time()

        # Stop workers
        for idx in xrange(self.n_jobs):
            write_queue.put(None)
            self.processes[idx].terminate()
            cleanup.unregister_proc(self.processes[idx].pid)

    def write_hyps(self, filename):
        with open(filename, 'w') as f:
            if self.force_dec or self.nbest > 1:
                for idx, (tr, sc) in enumerate(zip(self.trans, self.scores)):
                    if not isinstance(tr, list):
                        tr = [tr]
                        sc = [sc]
                    for t,s in zip(tr, sc):
                        # Convert to actual words
                        f.write("%d ||| %s ||| %.6f\n" % (idx, idx_to_sent(self.ref_idict, t), s))
            else:
                f.write("\n".join([idx_to_sent(self.ref_idict, s) for s in self.trans]))
                f.write("\n")

    def compute_score(self, hyp_file, scorers):
        results = {}
        for scorer in scorers:
            c = get_scorer(scorer)()
            score = c.compute(self.ref_files, hyp_file)
            results[scorer] = (str(score), score.score)
        return results

if __name__ == "__main__":
    parser = argparse.ArgumentParser(prog='translate')
    parser.add_argument('-j', '--n-jobs'        , type=int, default=8,
                                                  help="Number of processes (default: 8, 0: Auto")
    parser.add_argument('-a', '--argmax'        , action="store_true",
                                                  help="Use argmax (1-best) instead of beam search")
    parser.add_argument('-b', '--beam-size'     , type=int, default=12,
                                                  help="Beam size (only for beam-search case)")
    parser.add_argument('-N', '--nbest'         , type=int, default=1,
                                                  help="Output n-best list size (only for beam-search case)")
    parser.add_argument('-f', '--force-decoding', help="Obtain TM scores for the given reference set instead of translation",
                                                  action="store_true")
    parser.add_argument('-r', '--seed'          , type=int, default=1234,
                                                  help="Random number seed (default: 1234)")
    parser.add_argument('-d', '--device'        , default='cpu', help="Where to run beam search.")

    parser.add_argument('-m', '--model'         , type=str, help="Model file", required=True)
    parser.add_argument('-M', '--metrics'       , type=str, help="Comma separated list of metrics (blue or bleu,meteor)", default="bleu")
    parser.add_argument('-p', '--pkl-file'      , type=str, help="pkl file (default: <model_file>.pkl)", default=None)
    parser.add_argument('-o', '--saveto'        , type=str, help="Output translations file (if not given, only metrics will be printed)",
                                                  default=None)

    parser.add_argument('-S', '--src-file'      , type=str, help="Source data (default: validation set)",
                                                  default=None)
    parser.add_argument('-R', '--ref-files'     , type=str, help="Reference files delimited by comma or * wildcard (default: validation set)",
                                                  default=None)

    args = parser.parse_args()
    if args.device.startswith("gpu"):
        args.n_jobs = 1
    elif args.device.startswith("cpu"):
        if args.n_jobs == 0:
            # Auto infer CPU number
            args.n_jobs = (cpu_count() / 2) - 1

        if args.n_jobs > 1:
            # This is to avoid thread explosion. Allow
            # each process to use a single thread.
            os.environ["OMP_NUM_THREADS"] = "1"
            os.environ["MKL_NUM_THREADS"] = "1"

    # Select device
    os.environ["THEANO_FLAGS"] = "device=%s" % args.device

    translator = Translator(beam_size=args.beam_size, src_file=args.src_file,
                            ref_files=args.ref_files, nbest=args.nbest,
                            n_jobs=args.n_jobs,
                            seed=args.seed, force_dec=args.force_decoding, argmax=args.argmax)

    # load model options
    if not args.pkl_file:
        args.pkl_file = args.model + ".pkl"

    with open(args.pkl_file, 'rb') as f:
        model_options = cPickle.load(f)

    translator.set_model_options(model_options, args.model)
    translator.set_model_params()
    translator.start()

    out_file = args.saveto
    if not args.saveto:
        hypf = get_temp_file(suffix=".nbest_hyps")
        out_file = hypf.name
        hypf.close()

    translator.write_hyps(out_file)

    if translator.ref_files:
        # Compute all metrics
        results = translator.compute_score(out_file, args.metrics.split(","))
        # NOTE: This dict is expected from nmt-translate for obtaining the validation results.
        print results

    sys.exit(0)
